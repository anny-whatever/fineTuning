{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098075de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Optimal sequence length for medical prescriptions (short responses)\n",
    "max_seq_length = 1024\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,  # Auto-detect best dtype\n",
    "    load_in_4bit=True,  # 4-bit quantization for efficiency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38087afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  # LoRA rank - balanced for medical precision\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,  # Scaling factor (typically = r)\n",
    "    lora_dropout = 0,  # 0 is optimized for Unsloth\n",
    "    bias = \"none\",  # \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\",  # 30% less VRAM\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma\",  # Gemma-2 uses \"gemma\" template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4912202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mental health counseling data\n",
    "dataset_raw = load_dataset(\"MaggiePai/mental_health_counseling_conversations\", split=\"train\")\n",
    "\n",
    "# Print dataset info\n",
    "print(f\"Dataset: {dataset_raw}\")\n",
    "print(f\"Number of examples: {len(dataset_raw)}\")\n",
    "print(f\"Dataset features: {dataset_raw.features}\")\n",
    "print(\"\\nFirst example:\")\n",
    "print(dataset_raw[0])\n",
    "\n",
    "# Cut dataset to first 100 samples for faster training\n",
    "dataset_raw = dataset_raw.select(range(100))\n",
    "print(f\"Dataset reduced to: {len(dataset_raw)} samples\")\n",
    "print(f\"Dataset Length: {len(dataset_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0fc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to chat format for mental health counseling\n",
    "def convert_to_chat_format(item):\n",
    "    \"\"\"Convert mental health counseling data to chat conversation format\"\"\"\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a compassionate and professional mental health counselor. Listen carefully to the client's concerns and provide empathetic, supportive, and constructive guidance.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": item['Context']\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": item['Response']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return {\"conversation\": conversation}\n",
    "\n",
    "# Convert all data to chat format\n",
    "chat_data = [convert_to_chat_format(item) for item in dataset_raw]\n",
    "\n",
    "print(f\"Converted {len(chat_data)} conversations\")\n",
    "print(\"\\nFirst conversation sample:\")\n",
    "print(chat_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset from chat data\n",
    "dataset = Dataset.from_list(chat_data)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(\"\\nFirst formatted conversation:\")\n",
    "print(dataset[0]['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0890a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format conversations with chat template\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversation\"]\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "        for convo in convos\n",
    "    ]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "print(\"Formatted prompt sample:\")\n",
    "print(dataset[0]['text'][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Optimal training configuration for mental health counseling data\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = None,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 50,\n",
    "        num_train_epochs = 3,\n",
    "        learning_rate = 2e-5,\n",
    "        logging_steps = 50,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 42,\n",
    "        output_dir = \"../models/therapist-chatbot\",\n",
    "        save_strategy = \"epoch\",\n",
    "        save_total_limit = 2,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf369b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train only on model responses (not user inputs or system prompts)\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<start_of_turn>user\\n\",\n",
    "    response_part = \"<start_of_turn>model\\n\",\n",
    ")\n",
    "\n",
    "print(\"Training dataset preview:\")\n",
    "print(f\"Total examples: {len(trainer.train_dataset)}\")\n",
    "print(f\"Sample input_ids length: {len(trainer.train_dataset[0]['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74104835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify training setup - check what parts are being trained\n",
    "sample_idx = 10\n",
    "print(\"Full prompt:\")\n",
    "print(tokenizer.decode(trainer.train_dataset[sample_idx][\"input_ids\"]))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Only training on (labels != -100):\")\n",
    "print(tokenizer.decode([x if x != -100 else tokenizer.pad_token_id for x in trainer.train_dataset[sample_idx][\"labels\"]]).replace(tokenizer.pad_token, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b20be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"ðŸš€ Starting training...\")\n",
    "print(f\"Total steps: ~{len(dataset) * 3 // (2 * 4)} steps (3 epochs, batch_size=2, grad_accum=4)\")\n",
    "print(f\"Training on {len(dataset)} mental health counseling conversations\")\n",
    "print(\"Expected training time: 1-2 hours depending on GPU\\n\")\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")\n",
    "print(f\"Final loss: {trainer_stats.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable fast inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def get_counseling_response(client_message, max_new_tokens=512, temperature=0.7):\n",
    "    \"\"\"Get counseling response from fine-tuned therapist model\"\"\"\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a compassionate and professional mental health counselor. Listen carefully to the client's concerns and provide empathetic, supportive, and constructive guidance.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": client_message\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "    return response\n",
    "\n",
    "# Test with mental health concerns\n",
    "test_cases = [\n",
    "    \"I'm feeling really anxious about my future and I don't know what to do.\",\n",
    "    \"I can't seem to get along with my family. We argue all the time.\",\n",
    "    \"I've been feeling really depressed lately and nothing seems to help.\",\n",
    "    \"My partner and I are having communication problems.\",\n",
    "    \"I'm struggling with low self-esteem and confidence.\",\n",
    "]\n",
    "\n",
    "print(\"ðŸ’¬ Testing Fine-tuned Therapist Chatbot\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "for concern in test_cases:\n",
    "    print(f\"CLIENT: {concern}\")\n",
    "    response = get_counseling_response(concern)\n",
    "    print(f\"THERAPIST: {response}\")\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d24681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "print(\"ðŸ’¾ Saving fine-tuned model...\")\n",
    "\n",
    "# Save LoRA adapter\n",
    "model.save_pretrained(\"../models/therapist-chatbot-lora\")\n",
    "tokenizer.save_pretrained(\"../models/therapist-chatbot-lora\")\n",
    "\n",
    "print(\"âœ… LoRA adapter saved to ../models/therapist-chatbot-lora\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
