{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0f6f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory allocated before: 0.00 GB\n",
      "GPU Memory reserved before: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Check GPU memory before offloading\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory allocated before: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU Memory reserved before: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19d49fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found in memory\n",
      "GPU cache cleared\n",
      "Garbage collection completed\n",
      "\n",
      "✓ Model offloaded from GPU successfully!\n"
     ]
    }
   ],
   "source": [
    "# Offload model from GPU\n",
    "try:\n",
    "    # Delete model object if it exists\n",
    "    if 'model' in globals():\n",
    "        del model\n",
    "        print(\"Model deleted from memory\")\n",
    "    else:\n",
    "        print(\"No model found in memory\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"GPU cache cleared\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    print(\"Garbage collection completed\")\n",
    "    \n",
    "    print(\"\\n✓ Model offloaded from GPU successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during offloading: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90842af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory allocated after: 0.00 GB\n",
      "GPU Memory reserved after: 0.00 GB\n",
      "\n",
      "Memory freed: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU memory after offloading\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory allocated after: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU Memory reserved after: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    print(f\"\\nMemory freed: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6552d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA contexts reset for all devices\n",
      "\n",
      "GPU Memory after aggressive cleanup: 0.00 GB\n",
      "GPU Memory reserved after cleanup: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Force reset CUDA context (WSL-specific fix)\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Reset all CUDA devices\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    \n",
    "    print(\"CUDA contexts reset for all devices\")\n",
    "    \n",
    "    # Additional aggressive cleanup\n",
    "    gc.collect()\n",
    "    \n",
    "    # Check memory again\n",
    "    print(f\"\\nGPU Memory after aggressive cleanup: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU Memory reserved after cleanup: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
